{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Some data checks and analysis\n",
    "First import and install necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Downloading https://files.pythonhosted.org/packages/72/5c/ec84c7ec49fde2c3b0d885ecae4504fa40fc77fef7684e9f2939c50f9b94/s3fs-0.4.0-py3-none-any.whl\n",
      "Collecting fsspec>=0.6.0 (from s3fs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/1f/7028dacd3c28f34ce48130aae73a88fa5cc27b6b0e494fcf2739f7954d9d/fsspec-0.6.2-py3-none-any.whl (62kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 6.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting boto3>=1.9.91 (from s3fs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/57/e9675a5a8d0ee586594ff19cb9a601334fbf24fa2fb29052d2a900ee5d23/boto3-1.11.9-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 9.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore>=1.12.91 (from s3fs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/4c/b0b0d3b6f84a05f9135051b56d3eb8708012a289c4b82ee21c8c766f47b5/botocore-1.14.9-py2.py3-none-any.whl (5.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.9MB 4.8MB/s eta 0:00:01    16% |█████▏                          | 952kB 28.1MB/s eta 0:00:01    39% |████████████▌                   | 2.3MB 27.6MB/s eta 0:00:01    62% |████████████████████            | 3.7MB 28.3MB/s eta 0:00:01    85% |███████████████████████████▌    | 5.0MB 29.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0 (from boto3>=1.9.91->s3fs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/48/a8252b6b3cd31774eab312b19d58a6ac55f296240c206617dcd38cd93bf8/s3transfer-0.3.2-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 16.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs) (0.9.3)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (1.22)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.11.0)\n",
      "\u001b[31mawscli 1.16.17 has requirement botocore==1.12.7, but you'll have botocore 1.14.9 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.16.17 has requirement s3transfer<0.2.0,>=0.1.12, but you'll have s3transfer 0.3.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: fsspec, botocore, s3transfer, boto3, s3fs\n",
      "  Found existing installation: botocore 1.12.7\n",
      "    Uninstalling botocore-1.12.7:\n",
      "      Successfully uninstalled botocore-1.12.7\n",
      "  Found existing installation: s3transfer 0.1.13\n",
      "    Uninstalling s3transfer-0.1.13:\n",
      "      Successfully uninstalled s3transfer-0.1.13\n",
      "  Found existing installation: boto3 1.9.7\n",
      "    Uninstalling boto3-1.9.7:\n",
      "      Successfully uninstalled boto3-1.9.7\n",
      "Successfully installed boto3-1.11.9 botocore-1.14.9 fsspec-0.6.2 s3fs-0.4.0 s3transfer-0.3.2\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, StringType, TimestampType\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import gc\n",
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create Spark session and increase broadcast timeout. The last step depends on the size of the cluster / machine, which is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = create_spark_session()\n",
    "spark.conf.set(\"spark.sql.broadcastTimeout\",  900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse artist table\n",
    "Let's have a look at the first rows and count the records. Apparently there are 10025 records on artists available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artistdf = spark.read.parquet(\"s3a://christophndde4/artist_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------+--------+---------+\n",
      "|         artist_id|           name|      location|latitude|longitude|\n",
      "+------------------+---------------+--------------+--------+---------+\n",
      "|ARQ6F0E1187FB45427|     Eisbrecher|              |    null|     null|\n",
      "|ARQ6JKR1187B99CC19|Grzegorz Turnau|Crakow, Poland|50.06007| 19.93259|\n",
      "+------------------+---------------+--------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artistdf.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10025"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse user table\n",
    "Apparently there are only 104 records, please also have at look at the readme.md concerning some restrictions of the user table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "userdf = spark.read.parquet(\"s3a://christophndde4/user_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     82|     Avery| Martinez|     F| paid|\n",
      "|     83|   Stefany|    White|     F| free|\n",
      "|     84|   Shakira|     Hunt|     F| free|\n",
      "|     85|   Kinsley|    Young|     F| free|\n",
      "|     85|   Kinsley|    Young|     F| paid|\n",
      "+-------+----------+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userdf.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse time table\n",
    "Apparently there ate 6820 unique timestamps in this dataframe, which were between Nov. 1st and Nov. 30th of 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "timedf = spark.read.parquet(\"s3a://christophndde4/time_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|          start_time|hour|day|week|weekday|year|month|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|2018-11-24 14:57:...|  14| 24|  47|      7|2018|   11|\n",
      "|2018-11-24 15:00:...|  15| 24|  47|      7|2018|   11|\n",
      "|2018-11-24 15:04:...|  15| 24|  47|      7|2018|   11|\n",
      "|2018-11-24 15:10:...|  15| 24|  47|      7|2018|   11|\n",
      "|2018-11-24 15:15:...|  15| 24|  47|      7|2018|   11|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timedf.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6820"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|     min(start_time)|     max(start_time)|\n",
      "+--------------------+--------------------+\n",
      "|2018-11-01 21:01:...|2018-11-30 19:54:...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timedf.agg(F.min(F.col(\"start_time\")), F.max(F.col(\"start_time\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse song table\n",
    "Apparently there are records 14896 for songs in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songdf = spark.read.parquet(\"s3a://christophndde4/song_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOAAAQN12AB01856D3|Campeones De La Vida|ARAMIDF1187FB3D8D4|   0|153.36444|\n",
      "|SOAACFC12A8C140567| Supernatural Pt. II|ARNHTE41187B99289A|   0|343.09179|\n",
      "|SOAACTC12AB0186A20|Christmas Is Comi...|ARXWFZ21187FB43A0B|2008|180.76689|\n",
      "|SOAADAD12A8C13D5B0|One Shot (Album V...|ARQTC851187B9B03AF|2005|263.99302|\n",
      "|SOAADJH12AB018BD30|Black Light (Albu...|AR3FKJ61187B990357|1975|385.90649|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songdf.orderBy(\"song_id\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14896"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse songplay (fact) table\n",
    "There are 333 records in this table. This is due to the fact that records without a song_id or an artist_is were not included here, since tbhis would not make much sense here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplaydf = spark.read.parquet(\"s3a://christophndde4/songplay_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|songplay_id|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|       3903|2018-11-29 20:21:...|     49| paid|SOABIXP12A8C135F75|AR15DJQ1187FB5910C|      1041|         Seattle, WA|Mozilla/5.0 (Wind...|\n",
      "|        992|2018-11-14 06:19:...|     80| paid|SOACRBY12AB017C757|ARVGCRM11F50C496F4|       548|                    |\"Mozilla/5.0 (Mac...|\n",
      "|       3369|2018-11-24 04:31:...|     29| paid|SOAECHX12A6D4FC3D9|ARX2DLI1187FB4DD03|       709|   Sydney, Australia|\"Mozilla/5.0 (Mac...|\n",
      "| 8589935354|2018-11-04 09:41:...|     44| paid|SOAFQGA12A8C1367FA|AR0IVTL1187B9AD520|       196|     Los Angeles, CA|Mozilla/5.0 (Maci...|\n",
      "|       1582|2018-11-28 21:05:...|     73| paid|SOAHVKA12A8C146C5F|ARPBMSQ1187B98AE69|       954|UK - England - So...|\"Mozilla/5.0 (Mac...|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplaydf.orderBy(\"song_id\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songplaydf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Please see the last section in the following notebook for explanations, why the songplay table is that small.\n",
    "https://github.com/ChristophGmeiner/NDDE3_DataWarehouse_AWS/blob/master/DataChecks.ipynbdde4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
