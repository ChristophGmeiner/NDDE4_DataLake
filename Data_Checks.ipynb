{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Some data checks and analysis\n",
    "First import and install necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: boto3>=1.9.91 in /opt/conda/lib/python3.6/site-packages (from s3fs) (1.11.9)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from s3fs) (0.6.2)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.6/site-packages (from s3fs) (1.14.9)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs) (0.3.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs) (0.9.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.14)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (1.22)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, StringType, TimestampType\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import gc\n",
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create Spark session and increase broadcast timeout. The last step depends on the size of the cluster / machine, which is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = create_spark_session()\n",
    "spark.conf.set(\"spark.sql.broadcastTimeout\",  900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse artist table\n",
    "Let's have a look at the first rows and count the records. Apparently there are 967 records on artists availabke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artistdf = spark.read.parquet(\"s3a://christophndde4/artist_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------+--------+---------+\n",
      "|         artist_id|           name|      location|latitude|longitude|\n",
      "+------------------+---------------+--------------+--------+---------+\n",
      "|ARQ6F0E1187FB45427|     Eisbrecher|              |    null|     null|\n",
      "|ARQ6JKR1187B99CC19|Grzegorz Turnau|Crakow, Poland|50.06007| 19.93259|\n",
      "+------------------+---------------+--------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artistdf.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10025"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse user table\n",
    "Apparently there are only 104 records, please also have at look at the readme.md concerning some restrictions of the user table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "userdf = spark.read.parquet(\"s3a://christophndde4/user_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     88|  Mohammad|Rodriguez|     M| free|\n",
      "|     88|  Mohammad|Rodriguez|     M| paid|\n",
      "|     29|Jacqueline|    Lynch|     F| free|\n",
      "|     29|Jacqueline|    Lynch|     F| paid|\n",
      "|     36|   Matthew|    Jones|     M| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userdf.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse time table\n",
    "Apparently there ate 6820 unique timestamps in this dataframe, which were between Nov. 1st and Nov. 30th of 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "timedf = spark.read.parquet(\"s3a://christophndde4/time_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-05 18:36:...|  18|  5|  45|   11|2018|      2|\n",
      "|2018-11-05 18:37:...|  18|  5|  45|   11|2018|      2|\n",
      "|2018-11-05 18:41:...|  18|  5|  45|   11|2018|      2|\n",
      "|2018-11-05 18:41:...|  18|  5|  45|   11|2018|      2|\n",
      "|2018-11-05 18:44:...|  18|  5|  45|   11|2018|      2|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timedf.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6820"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|     min(start_time)|     max(start_time)|\n",
      "+--------------------+--------------------+\n",
      "|2018-11-01 21:01:...|2018-11-30 19:54:...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timedf.agg(F.min(F.col(\"start_time\")), F.max(F.col(\"start_time\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse song table\n",
    "Apparently there are records in this table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songdf = spark.read.parquet(\"s3a://christophndde4/song_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOAAAQN12AB01856D3|Campeones De La Vida|ARAMIDF1187FB3D8D4|   0|153.36444|\n",
      "|SOAACFC12A8C140567| Supernatural Pt. II|ARNHTE41187B99289A|   0|343.09179|\n",
      "|SOAACTC12AB0186A20|Christmas Is Comi...|ARXWFZ21187FB43A0B|2008|180.76689|\n",
      "|SOAADAD12A8C13D5B0|One Shot (Album V...|ARQTC851187B9B03AF|2005|263.99302|\n",
      "|SOAADJH12AB018BD30|Black Light (Albu...|AR3FKJ61187B990357|1975|385.90649|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songdf.orderBy(\"song_id\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14896"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analyse songplay (fact) table\n",
    "There are records in this table. This is due to the fact that records without a song_id or an artist_is were not included here, since tbhis would not make much sense here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplaydf = spark.read.parquet(\"s3a://christophndde4/songplay_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|songplay_id|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|       3903|2018-11-29 20:21:...|     49| paid|SOABIXP12A8C135F75|AR15DJQ1187FB5910C|      1041|         Seattle, WA|Mozilla/5.0 (Wind...|\n",
      "|        992|2018-11-14 06:19:...|     80| paid|SOACRBY12AB017C757|ARVGCRM11F50C496F4|       548|                    |\"Mozilla/5.0 (Mac...|\n",
      "|       3369|2018-11-24 04:31:...|     29| paid|SOAECHX12A6D4FC3D9|ARX2DLI1187FB4DD03|       709|   Sydney, Australia|\"Mozilla/5.0 (Mac...|\n",
      "| 8589935354|2018-11-04 09:41:...|     44| paid|SOAFQGA12A8C1367FA|AR0IVTL1187B9AD520|       196|     Los Angeles, CA|Mozilla/5.0 (Maci...|\n",
      "|       1582|2018-11-28 21:05:...|     73| paid|SOAHVKA12A8C146C5F|ARPBMSQ1187B98AE69|       954|UK - England - So...|\"Mozilla/5.0 (Mac...|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplaydf.orderBy(\"song_id\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songplaydf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Please see the last sectiob in the following notebook for explanations, why the songplay table is that small.\n",
    "https://github.com/ChristophGmeiner/NDDE3_DataWarehouse_AWS/blob/master/DataChecks.ipynbdde4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
